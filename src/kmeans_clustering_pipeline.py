import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score

# Step 1: Load the data
def load_data(file_path):
    """Loads the dataset from a specified CSV file. Prints the dataset size upon successful loading."""
    try:
        data = pd.read_csv("data/force2020_data_unsupervised_learning.csv")
        print(f"Data successfully loaded. Dataset size: {data.shape}")
        return data
    except FileNotFoundError:
        print("File not found. Please verify the file path.")
        return None

# Step 2: Preprocess the data
def preprocess_data(data, columns_to_scale):
    """Scales the data and removes null values."""
    data = data.dropna()  # Remove null values
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(data[columns_to_scale])
    return scaled_data

# Step 3: Find the optimal number of clusters (Elbow Curve)
def plot_elbow_curve(data):
    """Generates the elbow curve to determine the optimal number of clusters."""
    inertia = []
    k_range = range(1, 11)
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(data)
        inertia.append(kmeans.inertia_)

    plt.figure(figsize=(8, 5))
    plt.plot(k_range, inertia, 'bo-')
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('Inertia')
    plt.title('Elbow Curve for K-Means')
    plt.show()

# Step 4: Train the K-Means model
def train_kmeans(data, n_clusters):
    """Trains the K-Means model with the specified number of clusters and returns the model and cluster labels."""
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(data)
    print(f"K-Means model trained with {n_clusters} clusters.")
    return kmeans, labels

# Step 5: Visualize the results
def plot_clusters(data, labels, kmeans):
    """Visualizes the clusters generated by K-Means (for 2D data or data reduced to 2D)."""
    if data.shape[1] > 2:
        print("The data has more than 2 dimensions. Consider reducing it before plotting.")
        return

    plt.figure(figsize=(8, 5))
    plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis', s=50, alpha=0.6, label='Data')
    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='X', s=200, label='Centroids')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title('Clusters generated by K-Means')
    plt.legend()
    plt.show()

# Pipeline execution
if __name__ == "__main__":
    # Path to the CSV file (adjust this path to your dataset)
    file_path = "data.csv"

    # Load data
    data = load_data(file_path)

    if data is not None:
        # Select columns for clustering (adjust according to your dataset)
        columns_to_scale = data.columns.tolist()  # Use all numeric columns

        # Preprocess data
        scaled_data = preprocess_data(data, columns_to_scale)

        # Determine the optimal number of clusters
        plot_elbow_curve(scaled_data)

        # Choose the number of clusters (adjust based on the elbow curve)
        n_clusters = 3

        # Train K-Means
        kmeans, labels = train_kmeans(scaled_data, n_clusters)

        # Visualize the clusters (for 2D data)
        if scaled_data.shape[1] == 2:
            plot_clusters(scaled_data, labels, kmeans)
        else:
            print("The data has more than 2 dimensions. Cannot plot directly.")
